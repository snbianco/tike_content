{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# How do I work with data in the cloud?\n",
    "***\n",
    "This Notebook will answer some \"first-time\" questions about working with cloud data. We'll then cover a basic example of cloud access syntax that you can copy for your own use.\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "- Describe the basic workflow for accessing data in the cloud\n",
    "- Apply this cloud workflow to your own data queries\n",
    "\n",
    "## Notebook Table of Contents\n",
    "- [Introduction](#Introduction)\n",
    "- [Imports and setup](#Imports-and-Setup)\n",
    "- [A Quick Query](#A-Quick-Query)\n",
    "- [Loading Files Directly into Memory](#Loading-Files-Directly-into-Memory)\n",
    "- [Bonus: Other Methods, Notes, and Caveats](#Bonus:-Other-methods,-Notes,-and-Caveats)\n",
    "    - [AWS Command Line Interface](#AWS-command-line-interface)\n",
    "    - [Integrated Methods](#Integrated-Methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "### What is \"the cloud\"? \n",
    "\n",
    "In this case, \"the cloud\" is the AWS East Datacenters in northern Virginia. By storing a cloud copy of MAST data here, we're able to offer our data in a new, highly accessible, highly available format. Cloud hosted data also permits users to interact with our data in new ways, as we'll see in the example below.\n",
    "\n",
    "### What datasets are available?\n",
    "\n",
    "The [MAST Archive](https://archive.stsci.edu/) offers a cloud copy of several mission datasets, including data from TESS, HST, GALEX, and more. They are generally cataloged in full on the [MAST Public Datasets](https://registry.opendata.aws/collab/stsci/) page, with a more condensed listing available on the [Public AWS Data](https://outerspace.stsci.edu/display/MASTDOCS/Public+AWS+Data) page.\n",
    "\n",
    "### How can I access cloud-hosted data?\n",
    "\n",
    "There are two approaches to accessing cloud-hosted data:\n",
    "1. While on TIKE, loading files directly into memory (recommended)\n",
    "2. A traditional download to your local machine from the cloud-hosted copy of MAST\n",
    "\n",
    "Whenever possible, it's best to use the first method. The vast majority of users, with small tweaks to existing code, should be able to access data this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imports and Setup\n",
    "\n",
    "We'll use the standard tools to open and plot a fits file:\n",
    "- `astropy.io fits` to read in the fits file\n",
    "- `matplotlib` to create the plot\n",
    "- `numpy` to automatically set brightness limits in the plot\n",
    "\n",
    "To access the cloud data, we need\n",
    "- `astroquery.mast` to search for and select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "from astroquery.mast import Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important step in this process is to enable cloud data access. Once we do, we'll be able to get cloud URIs and access files directly. If you're working locally, you can use this command to download data from the cloud copy of MAST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.enable_cloud_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Query\n",
    "\n",
    "Now we can begin our query. This is not a particularly interesting query, but makes for a quick, easily reproducable example. We'll look for a particular HST Observation, then keep only the minimum recommended science files from that observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# You likely wouldn't search on obs_id, but it makes this example reproducable\n",
    "obs = Observations.query_criteria(obs_id=\"ibxl50020\")\n",
    "\n",
    "# Get the products, then filter to keep science and MRP (minimum recommended products)\n",
    "prod = Observations.get_product_list(obs)\n",
    "filtered = Observations.filter_products(prod, mrp_only=True, productType='SCIENCE')\n",
    "\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular product is a combined, [\"drizzled\" FITS file](https://hst-docs.stsci.edu/drizzpac/chapter-3-description-of-the-drizzle-algorithm/3-2-drizzle-concept). Without bogging down this notebook in technical details, drizzled images are generally better-resolved. This specific drizzled image combines data from four Hubble instruments, and thus will make a particularly nice looking plot.\n",
    "\n",
    "Now that we've identified a file of interest, we need to locate its cloud URI: where the file is located on the S3 server. This is straightforward with the `get_cloud_uris` function, which allows us to pass a table of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_uri = Observations.get_cloud_uris(filtered)\n",
    "c_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that our cloud URI is in a **list**. When we access the file, we'll need to pass the location as a **string**. Let's fix that now and avoid errors later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_uri = c_uri[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files directly into memory\n",
    "Whether opening a file on the cloud, or on your local machine, it's best practice to close the file once you're done using it. This is most easily done using Python's `with/open` syntax, as we'll do below.\n",
    "\n",
    "**Note:** Code in the `with` statement should only be used to extract data from the file. Relatively slow computations and plot generation should go outside of this statement so that the file can close in a timely manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of passing a local file path,\n",
    "# pass the cloud URI into fits.open()\n",
    "with fits.open(c_uri, fsspec_kwargs={\"anon\": True}) as hdulist:\n",
    "    hdulist.info()\n",
    "    sci = hdulist[1].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've printed out some information about the file, and read the data from `HDU1` into a variable called `sci`. We can now use `sci` to create plots or images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust limits on image: stars are bright, empty space is very dark\n",
    "low = np.nanpercentile(sci, 1)\n",
    "high = np.nanpercentile(sci,99)\n",
    "\n",
    "# Plot sci in greyscale\n",
    "plt.imshow(sci, cmap='gray', vmin=low, vmax=high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a neat view of (a part of) the [Horsehead Nebula](https://hubblesite.org/contents/media/images/2013/12/3165-Image.html).\n",
    "\n",
    "Although this is an artificial example, it still demonstrates that reading data from the cloud is straightforward. With an extra line or two of code, users have access to terabytes of data, no downloads required. This is particularly useful for users with slow internet connections, limited storage, or without a personal computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Other methods, Notes, and Caveats\n",
    "\n",
    "This section is of limited value to the average user looking to analyze astronomical data. Here, we document additional ways to access cloud data that may be of interest to developers or those curious about our cloud infrastructure.\n",
    "\n",
    "### AWS command-line interface\n",
    "\n",
    "Since all of the cloud files are available to you as if they were local, it is possible to browse through them. This is not a very efficient way to find observations, but the AWS command-line interface does permit exploration within Jupyter Notebooks (by prefixing the command with `!`) and from a Terminal window (file › new › terminal).\n",
    "\n",
    "For example, we can list the contents of the TESS data held in the public MAST S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://stpubdata/tess/public/ --no-sign-request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a particularly insightful list, so if you wanted to explore in more detail:\n",
    "* `ffi/` holds the TESS full-frame images\n",
    "* `mast/` contains the TESS \"cubes\": [stacked FFI images](https://spacetelescope.github.io/mast_notebooks/notebooks/astrocut/making_tess_cubes_and_cutouts/making_tess_cubes_and_cutouts.html) that allow you to easily generate cutouts\n",
    "* `pixel_list` contains an incomplete list of targets and their associated pixels\n",
    "* `staged_cutouts/` is particularly unhelpful; it contains TESS cutouts requested by users. Filenames are randomly generated, so you will not find anything interesting by browsing.\n",
    "* `tid/` contains all of SPOC-derived TPFs and LCs, sorted by [TESS filename convention](https://archive.stsci.edu/missions-and-data/tess/data-products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this Notebook\n",
    "\n",
    "If you have comments or questions on this notebook, please contact us through the Archive Help Desk e-mail at archive@stsci.edu. If you spot any errors, open an issue on the [tike_content repository](https://github.com/spacetelescope/tike_content).\n",
    "\n",
    "**Author:** Thomas Dutkiewicz <br>\n",
    "**Keywords:** TIKE, AWS, Cloud <br>\n",
    "\n",
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TESS Environment",
   "language": "python",
   "name": "tess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
