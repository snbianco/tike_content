{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Public Kepler Data\n",
    "When accessing many gigabytes of data on S3, significant speed up can be gained by retrieving the data from the [S3 buckets](https://aws.amazon.com/s3/) (Amazon Web Service's secure filestore system) instead of pulling it from MAST in Baltimore, Maryland. \n",
    "\n",
    "This tutorial demonstrates how to do the following:\n",
    "\n",
    "- Use boto3, Amazon package for interacting with AWS services\n",
    "- Find the name of the Kepler data of interest\n",
    "- Transfer data from the bucket to the local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore #botocore will be needed to configure for free/anonymous access to the MAST AWS Public Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kepler science data are available in the public [s3://stpubdata/kepler/public](https://registry.opendata.aws/kepler/) S3 bucket on AWS.  We will use files in this bucket to demo transfering and reading a FITS formatted data file from an AWS S3 Bucket.\n",
    "\n",
    "To start, we will use the boto3 software to download the manifest file for the Kepler S3 public bucket, created by Kepler's archive, MAST. Listing all the files in a public bucket is not simple, so this file provides a way around that limitation. We will download the manifest.txt.gz file to our local file system using [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-download-file.html).  We do this by creating an s3 boto resource and specifying the bucket name, \"stpubdata\".  Then the download_file method acts like a copy command to transfer the file from the bucket into a filename of your choice in your local file system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure boto3 to use unsigned requests for anonymous access\n",
    "config = config = botocore.client.Config(signature_version=botocore.UNSIGNED)\n",
    "\n",
    "#Choose a resource\n",
    "s3 = boto3.resource('s3',config=config)\n",
    "#specify a bucket\n",
    "bucket = s3.Bucket('stpubdata')\n",
    "#Download the file from the bucket and call it manifest.txt.gz on the local filesystem.\n",
    "bucket.download_file(\"kepler/public/manifest.txt.gz\", \"manifest.txt.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you unzip the file you will see a listing of all the filenames stored in this public bucket. We will now transfer one of those files to our local file system in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using the S3 STScI public dataset [astroquery.mast.cloud]\n",
      "Downloading URL s3://stpubdata/kepler/public/lightcurves/0119/011904151/kplr011904151-2010009091648_llc.fits to ./mastDownload/Kepler/kplr011904151_lc_Q111111110111011101/kplr011904151-2010009091648_llc.fits ... [Done]\n"
     ]
    }
   ],
   "source": [
    "from astroquery.mast import Observations\n",
    "\n",
    "#Have astroquery attempt to retrieve from AWS first.\n",
    "Observations.enable_cloud_dataset(provider='AWS')\n",
    "\n",
    "target = \"Kepler-10\"\n",
    "\n",
    "#Do a cone search and find the Kepler long cadence data for your target\n",
    "obs = Observations.query_object(target,radius=\"0s\")\n",
    "want = (obs['obs_collection'] == \"Kepler\") & (obs['t_exptime'] ==1800.0)\n",
    "\n",
    "#Pick which data you want to retrieve\n",
    "data_prod = Observations.get_product_list(obs[want])\n",
    "filt_prod = Observations.filter_products(data_prod, description=\"Lightcurve Long Cadence (CLC) - Q4\")\n",
    "\n",
    "#Move data from the S3 bucket to the default astroquery location. \n",
    "#cloud_only=True means that data will only be retrieved if available on AWS S3\n",
    "manifest = Observations.download_products(filt_prod, cloud_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TESS Environment",
   "language": "python",
   "name": "tess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}